---
title: 'Persistent Volumes for your Kubernetes Cluster'
---

This document describes how PersistentVolumeClaims (PVCs) work in our managed Kubernetes product and how to configure them for workloads that require persistent data storage.

Every Ubicloud Kubernetes Cluster comes with a pre-installed UbiCSI add-on which you can find its source code [here](https://github.com/ubicloud/ubicloud/tree/main/kubernetes/csi). You can see that a StorageClass is defined and can be used for your PVCs.

```bash
kubectl get storageclasses
NAME                          PROVISIONER        RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
ubicloud-standard (default)   csi.ubicloud.com   Delete          WaitForFirstConsumer   false                  2h
```

All the UbiCSI appliaction are deployed in the `ubicsi` namespace for better seperation from other workloads.

## How it works

Managing distributed storage systems in Kubernetes is challenging, while using local disks alone risks data loss during pod restarts or node upgrades. Our CSI driver addresses this by provisioning PersistentVolumeClaims on local disks for speed and automatically migrating data when a node becomes unschedulable. This combines the performance of local storage with the reliability of managed persistence.

UbiCSI works by creating local disks on the node where the pod is scheduled. Using node affinities on the PersistentVolume, the PVC stays bound to that node, ensuring the pod always runs on the same host during normal restarts and as long as the node remains schedulable.

## Data Durability

For data durability, UbiCSI continuously monitors node health. When a pod restarts and its original node becomes unschedulable, UbiCSI automatically reschedules the pod on a healthy node and transfers the associated data to the new location. This ensures workloads remain available and data persists even when nodes fail or are taken out of service.

## Data Migration

When a pod is restarted on a node that becomes unschedulable, UbiCSI automatically begins migrating its data to a new host. The migration runs in the background, and during this process, the pod may temporarily return errors such as "Old PV data is not copied yet" These messages are expected and indicate that the data copy is still in progress. Users should avoid force deleting or restarting the pod, as doing so can disrupt the migration. Once the transfer completes, the pod resumes normal operation with its data fully available on the new node.

## Limitations
- Data migration relies on network bandwidth. Large volumes can slow pod restarts, so PVC size is limited to 10 GB to avoid excessive network strain.

- The size limit also helps maintain consistent migration performance across nodes.

- If a Kubernetes node is lost due to critical hardware failure, any data stored locally on that node is also lost.

If you need PVC disks bigger than 10 GB, you can reach out to us via support@ubicloud.com.
